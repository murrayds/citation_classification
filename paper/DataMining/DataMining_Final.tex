%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Arsclassica Article
% LaTeX Template
% Version 1.1 (1/8/17)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Lorenzo Pantieri (http://www.lorenzopantieri.net) with extensive modifications by:
% Vel (vel@latextemplates.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[
10pt, % Main document font size
a4paper, % Paper type, use 'letterpaper' for US Letter paper
oneside, % One page layout (no page indentation)
%twoside, % Two page layout (page indentation for binding and different headers)
headinclude,footinclude, % Extra spacing for the header and footer
BCOR5mm, % Binding correction
]{scrartcl}

\input{structure.tex} % Include the structure.tex file which specified the document structure and layout

\hyphenation{Fortran hy-phen-ation} % Specify custom hyphenation points in words with dashes where you would like hyphenation to occur, or alternatively, don't put any dashes in a word to stop hyphenation altogether

%----------------------------------------------------------------------------------------
%	TITLE AND AUTHOR(S)
%----------------------------------------------------------------------------------------

\title{\normalfont\spacedallcaps{An cluster-analysis investigation of the latent function of in-text citations}} % The article title

%\subtitle{Subtitle} % Uncomment to display a subtitle

\author{\spacedlowsmallcaps{Dakota Murray}} % The article author(s) - author affiliations need to be specified in the AUTHOR AFFILIATIONS block

\date{\today} % An optional date to appear under the author(s)

%----------------------------------------------------------------------------------------

\begin{document}

%----------------------------------------------------------------------------------------
%	HEADERS
%----------------------------------------------------------------------------------------

\renewcommand{\sectionmark}[1]{\markright{\spacedlowsmallcaps{#1}}} % The header for all pages (oneside) or for even pages (twoside)
%\renewcommand{\subsectionmark}[1]{\markright{\thesubsection~#1}} % Uncomment when using the twoside option - this modifies the header on odd pages
\lehead{\mbox{\llap{\small\thepage\kern1em\color{halfgray} \vline}\color{halfgray}\hspace{0.5em}\rightmark\hfil}} % The header style

\pagestyle{scrheadings} % Enable the headers specified in this block

%----------------------------------------------------------------------------------------
%	TABLE OF CONTENTS & LISTS OF FIGURES AND TABLES
%----------------------------------------------------------------------------------------

\maketitle % Print the title/author/date block

\setcounter{tocdepth}{2} % Set the depth of the table of contents to show sections and subsections only

\tableofcontents % Print the table of contents

\listoffigures % Print the list of figures

\listoftables % Print the list of tables

%----------------------------------------------------------------------------------------
%	ABSTRACT
%----------------------------------------------------------------------------------------

\section*{Abstract} % This section will not appear in the table of contents due to the star (\section*)

\lipsum[1] % Dummy text

%----------------------------------------------------------------------------------------
%	AUTHOR AFFILIATIONS
%----------------------------------------------------------------------------------------

\let\thefootnote\relax\footnotetext{* \textit{Indiana University—Bloomington, School of Informatics, Computing, and Engineering}}

%----------------------------------------------------------------------------------------

\newpage % Start the article content on the second page, remove this if you have a longer abstract that goes onto the second page

%----------------------------------------------------------------------------------------
%	INTRODUCTION
%----------------------------------------------------------------------------------------

\section{Introduction}

The citation constitutes one of the most basic unit of analysis in the fields of bibliometrics, scientometrics, and quantitative study of science. The h-index ~\cite{hirsch_index_2005}, journal-impact factor ~\cite{garfield_citation_1955}, and other evaluative tools have emerged from these disciplines and been put into widespread us. For better or worse, bibliometric indicators are now ubiquitous in the scientific ecosystem. Google Scholar publicly displays a an author’s h-index, most journals feature their journal impact factor prominently on their homepages, and universities use tools from companies like Academic Analytics that use citations to benchmark a department’s research performance. 

Given their present importance, it is worrisome that citation-count based metrics often fail as indicators of quality~\cite{leydesdorff_citations:_2016}. One criticism of citation-based evaluation (of many) is that citations do not necessarily represent an endorsement of a past work, but may instead reflect a host of other “non-scientific” meanings~\cite{bornmann_what_2006}. Bibliometric researchers have long attempted to create classification frameworks that capture the diversity of citation meanings~\cite{moravcsik_results_1975}, but such schemes have tended to require intensive manual effort. That the nature of citations cannot be determined at scale remains a pressing concern for any citation-based evaluation.

More recently, computational and natural language processing experts have developed techniques to automatically classify citations using in-text features and publication metadata ~\cite{jha_nlp-driven_2017}. Such studies have attempted to classify citations based on their supposed function ~\cite{teufel_automatic_2006}, sentiment~\cite{catalini_incidence_2015}, and importance ~\cite{valenzuela_identifying_2015}, and have attempted to address the technical, rather than social or theoretical issues. Despite some progress made by these researchers, citation classification remains an open and contentious problem.

The field of automatic citation classification have thus far opted for a “top-down” approach to the development of classification frameworks. However, these approaches have necessitated that researchers impose a model of citation onto their data, models which vary greatly between individual researchers and disciplines. Thus far, studies of automatic citation classification has produced little to no consensus on a best model or approach to citation classification. However, the massive quantities of structured full-text data of scientific publications that are now available allow for alternative approaches. 

In this study, I use an unsupervised, “bottom-up” approach to the study of the nuances and meanings of in-text citation using full-text data from all publications in the Journal of Informetrics. I employ a series of unsupervised clustering techniques on selected features of these in-text citations with the goal of revealing latent citation types. The features I extract are intended to maximize interpretability, rather than detail and complexity. The findings of this analysis will be used to inform future studies of citation classification. 

%----------------------------------------------------------------------------------------
%	METHODS
%----------------------------------------------------------------------------------------

\section{Methods}

\subsection{Data}
The data used in this analysis comes from the Elsevier ScienceDirect database. This dataset was originally obtained by the University of Leiden in 2017, and contains 4,821,774 english-language publications specifically labeled as “full-length article”, “short communication”, or “reviewer article” published between 1980 and 2016. Sentences containing in-text citations have been extracted from the full-text of these articles, and placed into a relational database hosted by the University of Leiden. More information on the Elsevier dataset, including a comparison to the existing PubMed dataset, and a large-scale descriptive analysis, can be found in a recent study by Boyack et al., ~\cite{boyack_characterizing_2018}. In this analysis, I focus primarily on the Journal of informetrics, a journal of relatively small size and of which I am familiar. There are 735 publications in the Journal of Informetrics, which corresponds to around 20,000 sentences containing in-text citations. This provides a manageable sample; any findings resulting from analysis of this limited data can easily be expanded to other journals and scientific disciplines. From these 20,000 sentences, we randomly sample 8,000; this smaller sample is more amenable to the analytica; 


\subsection{Selected Features}

Previous analysis of citation function have relied on a host of sophisticated features such as parts-of-speech-tagged N-grams of the sentence (Teufel, 2006; Athar, 2011; Li, 2013; Valenzuela, 2015) and sentence dependency structure (athar, 2011; Li, 2013; Jha, 2017). However, these approaches tend to produce large feature sets that, while often useful for classification, are difficult to interpret. In this early stage of analysis, I will instead focus on a smaller set of features that can be more readily interpreted.  

I represent each sentence in a feature-space using a simplified version of a bag-of-words model. I counted the occurrence of words in each sentence that appeared in each of 31 mutually-exclusive word-lists. These word-lists were originally crafted to study citation sentiment (Small, 2018), and words within each list were selected due to their having relevance within scientific writing. 

In addition to features extracted from the textual elements of each citation, past research has also demonstrated the usefulness of contextual features of the citation, such as its position in the paper (Teufel 2006; Valenzuela, 2015; Jha, 2017). Because of this, I included a feature containing the \textit{percentage} of progression of the citation through the paper, which is to say the index of the citation sentence in the paper divided by the total number of sentences. For example, if a sentence containing a citation is the 5th sentence in a paper with 200 total sentences, then it would have a sentence progression would be 0.025 percent. I also included a feature containing the number of citations in the citation sentence, and another variable representing the number of references in the paper. 

\subsection{Cluster generation and validation}
Once I construct a feature vector for all citation sentences, I will use unsupervised clustering techniques in an attempt to uncover latent citation function. Past research on citation function have tended to focus on \textit{classification}, rather than clustering. As such, there is little history of which methods work best. I will use three methods representing a range of common clustering techniques: k-means, DBscan, and hierarchical agglomerative clustering. 

To gain a sense of cluster quality, I embed the 35-dimensional feature space into a 2-dimensional feature space which can be plotted. I constructed a feature matrix by calculating the cosine distance (1 - cosine similarity) for each pair of points. I then used classical multidimensional-scaling to embed this distance matrix into 2-dimensional euclidean space. This approach of embedding a cosine distance matrix into euclidean space is not exactly mathematically "correct", but it produced good enough results. Classical multidimensional scaling has a computational complexity of $O(n^{3}$, and so scales poorly with larger data-sets; for this reason, I limit the final analysis to only n=8,000 sentences randomly selected from the original 20,000. 

I ran several iterations of each of the above clustering techniques, and choose the seemingly optimal clustering by examining how the clusters map onto the 2-dimensional embedding. I then assessed the utility of the clustering by attempting to classify each sentence into its assigned cluster category. High accuracy in task is evidence that the proposed clustering is robust and can be predicted from the provided features. I use three classification techniques: k-nearest neighbors, a simple Rpart decision tree, and random forests. I run each through a series of parameter turnings and train each using 10-fold cross validation. 


%----------------------------------------------------------------------------------------
%	RESULTS AND DISCUSSION
%----------------------------------------------------------------------------------------

\section{Results and Discussion}

These are some results and discussions

\section{Conclusion}

This is a conclusion

%----------------------------------------------------------------------------------------
%	BIBLIOGRAPHY
%----------------------------------------------------------------------------------------
\newpage
\renewcommand{\refname}{\spacedlowsmallcaps{References}} % For modifying the bibliography heading

\bibliographystyle{unsrt}


\bibliography{datamining.bib} % The file containing the bibliography

%----------------------------------------------------------------------------------------

\end{document}